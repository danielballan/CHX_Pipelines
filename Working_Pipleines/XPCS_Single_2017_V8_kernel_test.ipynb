{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XPCS&XSVS Pipeline for Single-(Gi)-SAXS Run\n",
    "\"This notebook corresponds to version {{ version }} of the pipeline tool: https://github.com/NSLS-II/pipelines\"\n",
    "\n",
    "This notebook begins with a raw time-series of images and ends with $g_2(t)$ for a range of $q$, fit to an exponential or stretched exponential, and a two-time correlation functoin.\n",
    "\n",
    "## Overview\n",
    "\n",
    "* Setup: load packages/setup path\n",
    "* Load Metadata & Image Data\n",
    "* Apply Mask\n",
    "* Clean Data: shutter open/bad frames\n",
    "* Get Q-Map\n",
    "* Get 1D curve\n",
    "* Define Q-ROI (qr, qz)\n",
    "* Check beam damage\n",
    "* One-time Correlation\n",
    "* Fitting\n",
    "* Two-time Correlation\n",
    "The important scientific code is imported from the [chxanalys](https://github.com/yugangzhang/chxanalys/tree/master/chxanalys) and [scikit-beam](https://github.com/scikit-beam/scikit-beam) project. Refer to chxanalys and scikit-beam for additional documentation and citation information.\n",
    "\n",
    "### DEV\n",
    "* V8: Update visbility error bar calculation using pi = his/N +/- sqrt(his_i)/N\n",
    "*     Update normlization in g2 calculation uing 2D-savitzky golay (SG ) smooth\n",
    "\n",
    "## CHX Olog NoteBook\n",
    "CHX Olog (https://logbook.nsls2.bnl.gov/11-ID/)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Import packages for I/O, visualization, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda_envs/analysis-17Q3.0/lib/python3.6/site-packages/filestore/retrieve.py:15: UserWarning: Do not import filestore.retrieve, import filestore.api instead\n",
      "  warnings.warn(\"Do not import filestore.retrieve, \"\n",
      "/opt/conda_envs/analysis-17Q3.0/lib/python3.6/site-packages/chxtools/handlers.py:67: UserWarning: fs is deprecated, use `db.reg` instead\n",
      "  db.fs.register_handler('AD_EIGER', LazyEigerHandler)\n",
      "/opt/conda_envs/analysis-17Q3.0/lib/python3.6/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "from chxanalys.chx_packages import *\n",
    "%matplotlib notebook\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "plt.rcParams.update({ 'image.origin': 'lower'   })\n",
    "plt.rcParams.update({ 'image.interpolation': 'none'   })\n",
    "import pickle as cpk\n",
    "from chxanalys.chx_xpcs_xsvs_jupyter_V1 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        var nb = IPython.notebook;\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        var command = \"NFP = '\" + nb.base_url + nb.notebook_path + \"'\";        \n",
       "        kernel.execute(command);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Javascript( '''\n",
    "        var nb = IPython.notebook;\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        var command = \"NFP = '\" + nb.base_url + nb.notebook_path + \"'\";        \n",
    "        kernel.execute(command);\n",
    "        ''' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print( 'The current running pipeline is: %s' %NFP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%reset -f -s dhist in out array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Runs Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scat_geometry = 'saxs'  #suport 'saxs', 'gi_saxs', 'ang_saxs' (for anisotropics saxs or flow-xpcs)\n",
    "scat_geometry = 'saxs'\n",
    "qphi_analysis =  False\n",
    "#scat_geometry = 'ang_saxs'  #suport 'saxs', 'gi_saxs', 'ang_saxs' (for anisotropics saxs or flow-xpcs)\n",
    "#scat_geometry = 'gi_waxs'  #suport 'saxs', 'gi_saxs', 'ang_saxs' (for anisotropics saxs or flow-xpcs)\n",
    "                           # gi_waxs define a simple box-shaped ROI \n",
    "#scat_geometry = 'gi_saxs'\n",
    "force_compress = False #True   #force to compress data \n",
    "bin_frame = False   #generally make bin_frame as False\n",
    "para_compress = True    #parallel compress\n",
    "run_fit_form = False    #run fit form factor \n",
    "run_waterfall =  False   #run waterfall analysis\n",
    "run_profile_plot = False  #run prolfile plot for gi-saxs\n",
    "run_t_ROI_Inten = True  #run  ROI intensity as a function of time\n",
    "run_get_mass_center = False  # Analysis for mass center of reflective beam center\n",
    "run_invariant_analysis = False\n",
    "run_one_time =  True  #run  one-time\n",
    "#run_fit_g2 = True       #run  fit one-time, the default function is \"stretched exponential\"\n",
    "fit_g2_func = 'stretched'\n",
    "run_two_time =  True    #run  two-time\n",
    "run_four_time = True #True #False   #run  four-time\n",
    "run_xsvs=  False #False         #run visibility analysis\n",
    "att_pdf_report = True    #attach the pdf report to CHX olog\n",
    "qth_interest = 1 #the intested single qth             \n",
    "use_sqnorm = True    #if True, use sq to normalize intensity\n",
    "use_SG = False        #if True, use the Sawitzky-Golay filter for <I(pix)>\n",
    "use_imgsum_norm= True  #if True use imgsum to normalize intensity for one-time calculatoin\n",
    "pdf_version='_%s'%get_today_date()     #for pdf report name\n",
    "run_dose =  True  #run dose_depend analysis\n",
    "\n",
    "if scat_geometry == 'gi_saxs':run_xsvs= False;use_sqnorm=False\n",
    "if scat_geometry == 'gi_waxs':use_sqnorm = False\n",
    "if scat_geometry != 'saxs':qphi_analysis = False;scat_geometry_ = scat_geometry  \n",
    "else:scat_geometry_ = ['','ang_'][qphi_analysis]+ scat_geometry   \n",
    "if scat_geometry != 'gi_saxs':run_profile_plot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%run ~/chxanalys_link/chxanalys/chx_generic_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saxs'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scat_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taus=None;g2=None;tausb=None;g2b=None;g12b=None;taus4=None;g4=None;times_xsv=None;contrast_factorL=None; lag_steps = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a directory for saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from this analysis will be stashed in the directory /XF11ID/analysis/2017_3/hkoerner/Results/\n",
      "/XF11ID/analysis/2017_3/hkoerner/Results/\n"
     ]
    }
   ],
   "source": [
    "CYCLE= '2017_3'  #change clycle here\n",
    "\n",
    "#CYCLE= '2017_2'  #change clycle here\n",
    "path = '/XF11ID/analysis/%s/masks/'%CYCLE\n",
    "username =  getpass.getuser()\n",
    "#username =  'rmhanna'\n",
    "username = 'hkoerner'\n",
    "#username = 'rheadric'\n",
    "\n",
    "data_dir0  = create_user_folder(CYCLE, username)\n",
    "print( data_dir0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ROI defined by \"XPCS_Setup\" Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/XF11ID/analysis/2017_3/masks/roi_mask_Nov17_Rings.pkl\n"
     ]
    }
   ],
   "source": [
    "# dynamic mask\n",
    "fp = '/XF11ID/analysis/2017_3/masks/roi_mask_Nov17_Rings.pkl'\n",
    "\n",
    "\n",
    "\n",
    "roi_mask,qval_dict = cpk.load( open(fp, 'rb' )  )  #for load the saved roi data\n",
    "print(fp)\n",
    "\n",
    "# q map file\n",
    "if scat_geometry =='gi_saxs':\n",
    "    # static mask\n",
    "    fp = data_dir0 + 'June_2017_Sam3_Graphene_no1_C60_200C_roi_static.pkl'\n",
    "    roi_masks,qval_dicts = cpk.load( open(fp, 'rb' )  )  #for load the saved roi data\n",
    "    print(fp)\n",
    "    fp = data_dir0 + 'June_2017_Sam3_Graphene_no1_C60_200C_gisaxs_qmap.pkl'\n",
    "    print(fp)\n",
    "    qr_map, qz_map, ticks, Qrs, Qzs,  Qr, Qz, inc_x0,refl_x0, refl_y0 = cpk.load( open(fp, 'rb' )  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run chxanalys_link/chxanalys/chx_generic_functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Metadata & Image Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change this line to give a uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uid = '76f314' # (scan num: 9401) (Measurement: 750Hz 1k frames mbs =.05x.4 CoralPor )   \n",
    "uid = 'ec4b0c' # (scan num: 9402) (Measurement: 750Hz 1k frames mbs =.1x.4 CoralPor )\n",
    "uid = '6d0761' #(scan num: 9403 (Measurement: 750Hz 5k frames 1000A        \"\n",
    "uid = 'c298d2' #(scan num: 9404 (Measurement: 100Hz 5k T=.2 1000A      \n",
    "uid = 'f03425' #(scan num: 9405 (Measurement: 10Hz 5k T=.2 1000A \n",
    "uid = 'b3ea84' #(scan num: 9406 (Measurement: 10Hz 5k T=.036 1000A        \"\n",
    "uid = 'be6e4c' #(scan num: 9407 (Measurement: 10Hz 5k T=.036 1000E        \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"   uid = '98811a' #(scan num: 10712 (Measurement: Beam profile smp_x (H) 0.2 x 0.2         \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_last_uids( -1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EigerHandler2_v2(EigerHandler2):\n",
    "    def get_file_list(self, datum_kwarg_gen):\n",
    "        return ['{}_{}_master.h5'.format(self._base_path, datum_kwargs['seq_id'])\n",
    "               for datum_kwargs in datum_kwarg_gen]\n",
    "\n",
    "db.reg.register_handler('AD_EIGER2', EigerHandler2_v2, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9407,\n",
       " 'be6e4c92-3af2-44a7-a6e9-0e09c145aa9c',\n",
       " ['/XF11ID/data/2017/11/17/7994774d-7d6e-4804-92eb_937_master.h5'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sid_filenames(header):\n",
    "    filepaths = []\n",
    "    db = header.db\n",
    "    # get files from assets\n",
    "    res_uids = db.get_resource_uids(header)\n",
    "    for uid in res_uids:\n",
    "        datum_gen = db.reg.datum_gen_given_resource(uid)\n",
    "        datum_kwarg_gen = (datum['datum_kwargs'] for datum in\n",
    "                           datum_gen)\n",
    "        filepaths.extend(db.reg.get_file_list(uid, datum_kwarg_gen))\n",
    "    return header.start['scan_id'],  header.start['uid'], filepaths\n",
    "\n",
    "get_sid_filenames(db[uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan_id, full-uid, data path are:  9407--be6e4c92-3af2-44a7-a6e9-0e09c145aa9c--['/XF11ID/data/2017/11/17/7994774d-7d6e-4804-92eb_937_master.h5']\n"
     ]
    }
   ],
   "source": [
    "sud = get_sid_filenames(db[uid])\n",
    "print ('scan_id, full-uid, data path are:  %s--%s--%s'%(sud[0], sud[1], sud[2] ))\n",
    "#start_time, stop_time = '2017-2-24  12:23:00', '2017-2-24  13:42:00' \n",
    "#sids, uids, fuids  = find_uids(start_time, stop_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from this analysis will be stashed in the directory /XF11ID/analysis/2017_3/hkoerner/Results/be6e4c/\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(data_dir0, '%s/'%uid)\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "print('Results from this analysis will be stashed in the directory %s' % data_dir)\n",
    "uidstr = 'uid=%s'%uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't Change these lines below here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_meta_data( uid,*argv,**kwargs ):\n",
    "    '''\n",
    "    Y.G. Dev Dec 8, 2016\n",
    "    \n",
    "    Get metadata from a uid\n",
    "    \n",
    "    - Adds detector key with detector name\n",
    "    \n",
    "    Parameters:\n",
    "        uid: the unique data acquisition id\n",
    "        kwargs: overwrite the meta data, for example \n",
    "            get_meta_data( uid = uid, sample = 'test') --> will overwrtie the meta's sample to test\n",
    "    return:\n",
    "        meta data of the uid: a dictionay\n",
    "        with keys:\n",
    "            detector            \n",
    "            suid: the simple given uid\n",
    "            uid: full uid\n",
    "            filename: the full path of the data\n",
    "            start_time: the data acquisition starting time in a human readable manner\n",
    "        And all the input metadata\n",
    "    '''\n",
    "\n",
    "    import time    \n",
    "    header = db[uid]\n",
    "    # print(header.start)\n",
    "    md ={}\n",
    "    md['detector'] = get_detector(header)\n",
    "    md['suid'] = uid  #short uid\n",
    "    md['filename'] = get_sid_filenames(db[uid])[2][0]\n",
    "\n",
    "    for dec in header.devices():\n",
    "        md.update(header.config_data(dec)['primary'][0])\n",
    "    \n",
    "    # for k,v in ev['descriptor']['configuration'][dec]['data'].items():\n",
    "    #     md[ k[len(dec)+1:] ]= v\n",
    "    \n",
    "    md.update(header.start['plan_args'].items())\n",
    "    md.update(header.start.items())\n",
    "    md.pop('plan_args')\n",
    "    \n",
    "    # print(header.start.time)\n",
    "    md['start_time'] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(header.start['time']))\n",
    "    md['stop_time'] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime( header.stop['time']))  \n",
    "    md['img_shape'] = header['descriptors'][0]['data_keys'][md['detector']]['shape'][:2][::-1]\n",
    "    md.update(kwargs)\n",
    "\n",
    "    #for k, v in sorted(md.items()):\n",
    "        # ...\n",
    "    #    print(f'{k}: {v}')\n",
    "    \n",
    "    return md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = get_meta_data( uid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Measurement': '10Hz 5k T=.036 1000E',\n",
       " 'T_sample': '16.591',\n",
       " 'T_yoke': '16.591',\n",
       " 'acquire period': '0.1',\n",
       " 'beamline_id': 'CHX',\n",
       " 'data path': '/XF11ID/data/2017/11/17/',\n",
       " 'detector': 'eiger4m_single_image',\n",
       " 'detectors': ['eiger4m_single'],\n",
       " 'eiger4m_single_beam_center_x': 1056.0,\n",
       " 'eiger4m_single_beam_center_y': 1236.0,\n",
       " 'eiger4m_single_cam_acquire_period': 0.1,\n",
       " 'eiger4m_single_cam_acquire_time': 0.09999000281095505,\n",
       " 'eiger4m_single_cam_num_images': 5000,\n",
       " 'eiger4m_single_det_distance': 10.083508845000003,\n",
       " 'eiger4m_single_photon_energy': 9653.0,\n",
       " 'eiger4m_single_threshold_energy': 4826.5,\n",
       " 'eiger4m_single_wavelength': 1.2844109535217285,\n",
       " 'exposure time': '0.1',\n",
       " 'feedback_x': 'on',\n",
       " 'feedback_y': 'on',\n",
       " 'filename': '/XF11ID/data/2017/11/17/7994774d-7d6e-4804-92eb_937_master.h5',\n",
       " 'hints': {'dimensions': [[['time'], 'primary']]},\n",
       " 'img_shape': [2167, 2070],\n",
       " 'num': 1,\n",
       " 'num_intervals': 0,\n",
       " 'num_points': 1,\n",
       " 'number of images': '5000',\n",
       " 'owner': 'xf11id',\n",
       " 'plan_name': 'count',\n",
       " 'plan_type': 'generator',\n",
       " 'run': '2017-3',\n",
       " 'sample': '1000E',\n",
       " 'scan_id': 9407,\n",
       " 'sequence id': '937.0',\n",
       " 'shutter mode': 'single',\n",
       " 'start_time': '2017-11-17 14:03:38',\n",
       " 'stop_time': '2017-11-17 14:12:07',\n",
       " 'suid': 'be6e4c',\n",
       " 'time': 1510945418.1920671,\n",
       " 'transmission': 0.03621108237460572,\n",
       " 'uid': 'be6e4c92-3af2-44a7-a6e9-0e09c145aa9c',\n",
       " 'user': 'hkoerner'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(uid, detector='eiger4m_single_image', fill=True, reverse=False):\n",
    "    \"\"\"load bluesky scan data by giveing uid and detector\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    uid: unique ID of a bluesky scan\n",
    "    detector: the used area detector\n",
    "    fill: True to fill data\n",
    "    reverse: if True, reverse the image upside down to match the \"real\" image geometry (should always be True in the future)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    image data: a pims frames series\n",
    "    if not success read the uid, will return image data as 0\n",
    "    \n",
    "    Usuage:\n",
    "    imgs = load_data( uid, detector  )\n",
    "    md = imgs.md\n",
    "    \"\"\"   \n",
    "    hdr = db[uid]\n",
    "    ATTEMPTS = 2\n",
    "    for attempt in range(ATTEMPTS):\n",
    "        try:\n",
    "            ev, = hdr.events(fields=[detector], fill=fill) \n",
    "            break\n",
    "            \n",
    "        except Exception:     \n",
    "            print ('Trying again ...!')\n",
    "            if attempt == ATTEMPTS - 1:\n",
    "                # We're out of attempts. Raise the exception to help with debugging.\n",
    "                raise\n",
    "    else:\n",
    "        # We didn't succeed\n",
    "        raise Exception(\"Failed after {} repeated attempts\".format(ATTEMPTS))\n",
    "        \n",
    "    # TODO(mrakitin): replace with the lazy loader (when it's implemented):\n",
    "    imgs = db.get_images(hdr, detector)    \n",
    "    # imgs = list(hdr.data( detector ) )\n",
    "    \n",
    "    if len(imgs[0])>=1:\n",
    "        md = imgs[0].md\n",
    "        imgs = pims.pipeline(lambda img: img)(imgs[0])\n",
    "        imgs.md = md\n",
    "\n",
    "    if reverse:\n",
    "        md = imgs.md\n",
    "        imgs = reverse_updown( imgs )  # Why not np.flipud?\n",
    "        imgs.md = md\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda_envs/analysis-17Q3.0/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: Images and get_images are deprecated. Use Header.data(eiger4m_single_image) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline processed through proc_func. Original repr:\n",
      "    EigerImages2 processed through proc_func. Original repr:\n",
      "        <Frames>\n",
      "        Length: 5000 frames\n",
      "        Frame Shape: 2167 x 2070\n",
      "        Pixel Datatype: uint32\n"
     ]
    }
   ],
   "source": [
    "imgs = load_data(uid, md['detector'], reverse=True)\n",
    "print(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" style=\"width: 489\" />"
      ],
      "text/plain": [
       "Frame([[         0,          0,          0, ...,          0,          0,\n",
       "                 0],\n",
       "       [         0,          0,          0, ...,          0,          0,\n",
       "                 0],\n",
       "       [         0,          0,          0, ...,          0,          0,\n",
       "                 0],\n",
       "       ..., \n",
       "       [         0,          0,          0, ...,          0,          0,\n",
       "                 0],\n",
       "       [         0,          0,          0, ...,          0,          0,\n",
       "                 0],\n",
       "       [         0,          0,          0, ...,          0,          0,\n",
       "        4294967295]], dtype=uint32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beam_center_x': 1056.0,\n",
       " 'beam_center_y': 1236.0,\n",
       " 'binary_mask': array([[ True,  True,  True, ...,  True,  True, False],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ..., \n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]], dtype=bool),\n",
       " 'count_time': 0.099990003,\n",
       " 'detector_distance': 10.0835,\n",
       " 'frame_time': 0.1,\n",
       " 'framerate': 9.9999998509883898,\n",
       " 'incident_wavelength': 1.284411,\n",
       " 'pixel_mask': array([[0, 0, 0, ..., 0, 0, 4],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint32),\n",
       " 'x_pixel_size': 7.5000004e-05,\n",
       " 'y_pixel_size': 7.5000004e-05}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline processed through proc_func. Original repr:\n",
      "    EigerImages2 processed through proc_func. Original repr:\n",
      "        <Frames>\n",
      "        Length: 5000 frames\n",
      "        Frame Shape: 2167 x 2070\n",
      "        Pixel Datatype: uint32\n",
      "The data are: Pipeline processed through proc_func. Original repr:\n",
      "    EigerImages2 processed through proc_func. Original repr:\n",
      "        <Frames>\n",
      "        Length: 5000 frames\n",
      "        Frame Shape: 2167 x 2070\n",
      "        Pixel Datatype: uint32\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cam_acquire_period'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-7b93d91c2251>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'The data are: %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acquire period'\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cam_acquire_period'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exposure time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cam_acquire_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cam_acquire_period'"
     ]
    }
   ],
   "source": [
    "imgs = load_data(uid, md['detector'], reverse= True)\n",
    "print(imgs)\n",
    "md.update( imgs.md )\n",
    "Nimg = len(imgs);\n",
    "#if 'number of images'  not in list(md.keys()):\n",
    "md['number of images']  = Nimg\n",
    "pixel_mask =  1- np.int_( np.array( imgs.md['pixel_mask'], dtype= bool)  )\n",
    "print( 'The data are: %s' %imgs )\n",
    "\n",
    "md['acquire period' ] = md['cam_acquire_period']\n",
    "md['exposure time'] =  md['cam_acquire_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = db[uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be6e4c'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = list(h.data('eiger4m_single_image'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" style=\"width: 489\" />"
      ],
      "text/plain": [
       "Frame([[         0,          0,          0, ...,          0,          0,\n",
       "        4294967295],\n",
       "       [         0,          0,          0, ...,          0,          0,\n",
       "                 0],\n",
       "       [         0,          0,          0, ...,          0,          0,\n",
       "                 0],\n",
       "       ..., \n",
       "       [         0,          0,          0, ...,          0,          0,\n",
       "                 0],\n",
       "       [         0,          0,          0, ...,          0,          0,\n",
       "                 0],\n",
       "       [         0,          0,          0, ...,          0,          0,\n",
       "                 0]], dtype=uint32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from databroker.assets.handlers import HandlerBase\n",
    "import logging\n",
    "logger = logging.getLogger('placeholder')\n",
    "import dask.array as da\n",
    "\n",
    "class HDF5DatasetSliceHandler(HandlerBase):\n",
    "    \"\"\"\n",
    "    Handler for data stored in one Dataset of an HDF5 file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "        path to HDF5 file\n",
    "    key : string\n",
    "        key of the single HDF5 Dataset used by this Handler\n",
    "    frame_per_point : integer, optional\n",
    "        number of frames to return as one datum, default 1\n",
    "    swmr : bool, optional\n",
    "        Open the hdf5 file in SWMR read mode. Only used when mode = 'r'.\n",
    "        Default is False.\n",
    "    \"\"\"\n",
    "    def __init__(self, filename, key, frame_per_point=1, swmr=False):\n",
    "        self._fpp = frame_per_point\n",
    "        self._filename = filename\n",
    "        self._key = key\n",
    "        self._file = None\n",
    "        self._dataset = None\n",
    "        self._data_objects = dict()\n",
    "        self._swmr = swmr\n",
    "\n",
    "        logger.debug(\"filename = {}\".format(filename))\n",
    "        logger.debug(\"key = {}\".format(key))\n",
    "        logger.debug(\"frame_per_point = {}\".format(frame_per_point))\n",
    "        logger.debug(\"swmr = {}\".format(swmr))\n",
    "\n",
    "        self.open()\n",
    "\n",
    "    def get_file_list(self, datum_kwarg_gen):\n",
    "        return [self._filename]\n",
    "\n",
    "    def __call__(self, point_number):\n",
    "        # Don't read out the dataset until it is requested for the first time.\n",
    "        if self._dataset is None:\n",
    "            self._get_dataset()\n",
    "\n",
    "        if self._swmr:\n",
    "            logger.debug(\"Refreshing dataset(s)\")\n",
    "            [ds.refresh() for ds in self._dataset]\n",
    "\n",
    "        if point_number not in self._data_objects:\n",
    "            start = point_number * self._fpp\n",
    "            stop = (point_number + 1) * self._fpp\n",
    "            self._data_objects[point_number] = self._get_data_object(start,\n",
    "                                                                     stop)\n",
    "        return self._data_objects[point_number]\n",
    "\n",
    "    def _get_data_object(self, start, stop):\n",
    "        return ImageStack(self._dataset[0], start, stop)\n",
    "\n",
    "    def _get_dataset(self):\n",
    "        self._dataset = list()\n",
    "        for key in self._key:\n",
    "            _dataset = self._file[key]\n",
    "            self._dataset.append(self._file[key])\n",
    "\n",
    "    def open(self):\n",
    "        if self._file:\n",
    "            return\n",
    "\n",
    "        import h5py\n",
    "\n",
    "        self._file = h5py.File(self._filename, 'r', swmr=self._swmr)\n",
    "        logger.debug(\"file open mode = {}\".format(self._file.mode))\n",
    "\n",
    "    def close(self):\n",
    "        super(HDF5DatasetSliceHandler, self).close()\n",
    "        self._file.close()\n",
    "        self._file = None\n",
    "\n",
    "\n",
    "class AreaDetectorHDF5Handler(HDF5DatasetSliceHandler):\n",
    "    \"\"\"\n",
    "    Handler for the 'AD_HDF5' spec used by Area Detectors.\n",
    "    In this spec, the key (i.e., HDF5 dataset path) is always\n",
    "    '/entry/data/data'.\n",
    "    This handler returns a pims ImageSequence with the data\n",
    "    from from the HDF5 dataset.\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "        path to HDF5 file\n",
    "    frame_per_point : integer, optional\n",
    "        number of frames to return as one datum, default 1\n",
    "    \"\"\"\n",
    "    specs = {'AD_HDF5'} | HDF5DatasetSliceHandler.specs\n",
    "    autoregister = True\n",
    "\n",
    "    def __init__(self, filename, frame_per_point=1):\n",
    "        hardcoded_key = ['/entry/data/data']\n",
    "        super(AreaDetectorHDF5Handler, self).__init__(\n",
    "            filename=filename, key=hardcoded_key,\n",
    "            frame_per_point=frame_per_point)\n",
    "\n",
    "        \n",
    "class AreaDetectorHDF5DaskHandler(AreaDetectorHDF5Handler):\n",
    "    \"\"\"\n",
    "    Handler for the 'AD_HDF5' spec used by Area Detectors.\n",
    "    In this spec, the key (i.e., HDF5 dataset path) is always\n",
    "    '/entry/data/data'.\n",
    "    This handler returns a dask array which is formed by calling\n",
    "    `dask.da.from_array()` with the HDF5 dataset.\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "        path to HDF5 file\n",
    "    frame_per_point : integer, optional\n",
    "        number of frames to return as one datum, default 1\n",
    "    \"\"\"\n",
    "    specs = {'AD_HDF5'} | HDF5DatasetSliceHandler.specs\n",
    "    autoregister = False\n",
    "\n",
    "    def _get_dataset(self):\n",
    "        self._dataset = list()\n",
    "        for key in self._key:\n",
    "            _dataset = self._file[key]\n",
    "            self._dataset.append(da.from_array(self._file[key],\n",
    "                                               chunks=_dataset.chunks))\n",
    "            logger.debug(\"dask chunk size = {}\".format(_dataset.chunks))\n",
    "            \n",
    "class EigerHDF5DaskHandler(HandlerBase):\n",
    "    EIGER_MD_LAYOUT = {\n",
    "        'y_pixel_size': 'entry/instrument/detector/y_pixel_size',\n",
    "        'x_pixel_size': 'entry/instrument/detector/x_pixel_size',\n",
    "        'detector_distance': 'entry/instrument/detector/detector_distance',\n",
    "        'incident_wavelength': 'entry/instrument/beam/incident_wavelength',\n",
    "        'frame_time': 'entry/instrument/detector/frame_time',\n",
    "        'beam_center_x': 'entry/instrument/detector/beam_center_x',\n",
    "        'beam_center_y': 'entry/instrument/detector/beam_center_y',\n",
    "        'count_time': 'entry/instrument/detector/count_time',\n",
    "        'pixel_mask': 'entry/instrument/detector/detectorSpecific/pixel_mask',\n",
    "    }\n",
    "    specs = {'AD_EIGER2'}\n",
    "    def __init__(self, fpath, images_per_file):\n",
    "        # create pims handler\n",
    "        self.images_per_file = images_per_file\n",
    "        self._base_path = fpath\n",
    "        print(fpath)\n",
    "\n",
    "    def __call__(self, seq_id):\n",
    "        master_path = '{}_{}_master.h5'.format(self._base_path, seq_id)\n",
    "        self._handle = h5py.File(master_path, 'r')\n",
    "        try:\n",
    "            self._entry = self._handle['entry']['data']  # Eiger firmware v1.3.0 and onwards\n",
    "        except KeyError:\n",
    "            self._entry = self._handle['entry']          # Older firmwares\n",
    "#         with h5py.File(master_path, 'r') as f:\n",
    "#             md = {k: f[v].value for k, v in self.EIGER_MD_LAYOUT.items()}\n",
    "#         # the pixel mask from the eiger contains:\n",
    "#         # 1  -- gap\n",
    "#         # 2  -- dead\n",
    "#         # 4  -- under-responsive\n",
    "#         # 8  -- over-responsive\n",
    "#         # 16 -- noisy\n",
    "#         pixel_mask = md['pixel_mask']\n",
    "#         #pixel_mask[pixel_mask>0] = 1\n",
    "#         #pixel_mask[pixel_mask==0] = 2\n",
    "#         #pixel_mask[pixel_mask==1] = 0\n",
    "#         #pixel_mask[pixel_mask==2] = 1\n",
    "#         md['binary_mask'] = (md['pixel_mask'] == 0)\n",
    "#         md['framerate'] = 1./md['frame_time']\n",
    "        # TODO Return a multi-dimensional PIMS seq.\n",
    "        #elements_seq_list = sum(self._entry[k].shape[0] for k in self.valid_keys)\n",
    "        elements = list()\n",
    "        key_names = sorted(list(self._entry.keys()))\n",
    "        for keyname in key_names:\n",
    "            #print(f\"{keyname}\")\n",
    "            val = self._entry[keyname]\n",
    "            elements.append(da.from_array(val, chunks=val.chunks))\n",
    "        \n",
    "#        print(self.images_per_file)\n",
    "#        dataset = self._entry['data_{:06d}'.format(1 + (seq_id // self.images_per_file))]\n",
    "        \n",
    "        # img = dataset[i % self.images_per_file]\n",
    "        return da.concatenate(elements)\n",
    "    \n",
    "db.reg.register_handler('AD_EIGER2', EigerHDF5DaskHandler, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/XF11ID/data/2017/11/17/7994774d-7d6e-4804-92eb\n"
     ]
    }
   ],
   "source": [
    "def dask_images(header, field):\n",
    "    return da.stack(list(header.data(field)))\n",
    "\n",
    "#imgs = list(h.data('eiger4m_single_image'))\n",
    "imgs = dask_images(h, 'eiger4m_single_image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[         0,          0,          0, ...,          0,          0,\n",
       "         4294967295],\n",
       "        [         0,          0,          0, ...,          0,          0,\n",
       "                  0],\n",
       "        [         0,          0,          0, ...,          0,          0,\n",
       "                  0],\n",
       "        ..., \n",
       "        [         0,          0,          0, ...,          0,          0,\n",
       "                  0],\n",
       "        [         0,          0,          0, ...,          0,          0,\n",
       "                  0],\n",
       "        [         0,          0,          0, ...,          0,          0,\n",
       "                  0]],\n",
       "\n",
       "       [[         0,          0,          0, ...,          0,          0,\n",
       "         4294967295],\n",
       "        [         0,          0,          0, ...,          0,          0,\n",
       "                  0],\n",
       "        [         0,          0,          0, ...,          0,          0,\n",
       "                  0],\n",
       "        ..., \n",
       "        [         0,          0,          0, ...,          0,          0,\n",
       "                  0],\n",
       "        [         0,          0,          0, ...,          0,          0,\n",
       "                  0],\n",
       "        [         0,          0,          0, ...,          0,          0,\n",
       "                  0]]], dtype=uint32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0][100:102].compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video[5][:10][:10].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_dict( md,  ['suid', 'number of images', 'uid', 'scan_id', 'start_time', 'stop_time', 'sample', 'Measurement',\n",
    "                  'acquire period', 'exposure time',  \n",
    "         'det_distance', 'beam_center_x', 'beam_center_y', ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overwrite Some Metadata if Wrong Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define incident beam center (also define reflection beam center for gisaxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scat_geometry =='gi_saxs':\n",
    "    inc_x0 =  md['beam_center_x'] \n",
    "    inc_y0 =  imgs[0].shape[0] - md['beam_center_y'] \n",
    "    \n",
    "    refl_x0 =   1541  #md['beam_center_x']  \n",
    "    refl_y0 =   960  #imgs[0].shape[0] -  1758   \n",
    "    print( \"inc_x0, inc_y0, ref_x0,ref_y0 are: %s %s %s %s.\"%(inc_x0, inc_y0, refl_x0, refl_y0) )\n",
    "else:\n",
    "    inc_x0 =  imgs[0].shape[0] - md['beam_center_y']   \n",
    "    inc_y0=   md['beam_center_x']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpix, lambda_, Ldet,  exposuretime, timeperframe, center = check_lost_metadata(\n",
    "    md, Nimg, inc_x0 = inc_x0, inc_y0=   inc_y0, pixelsize = 7.5*10*(-5) )\n",
    "if scat_geometry =='gi_saxs':center=center[::-1]\n",
    "setup_pargs=dict(uid=uidstr, dpix= dpix, Ldet=Ldet, lambda_= lambda_, exposuretime=exposuretime,\n",
    "        timeperframe=timeperframe, center=center, path= data_dir)\n",
    "print_dict( setup_pargs )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setup_pargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Mask\n",
    "* load and plot mask if exist \n",
    "* otherwise create a mask using Mask pipeline\n",
    "* Reverse the mask in y-direction due to the coordination difference between python and Eiger software\n",
    "* Reverse images in y-direction\n",
    "* Apply the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the blow line to give mask filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scat_geometry == 'gi_saxs':\n",
    "    mask_path = '/XF11ID/analysis/2017_2/masks/'    \n",
    "    mask_name =  'Jun4_2_GiSAXS.npy'   \n",
    "\n",
    "    \n",
    "elif scat_geometry == 'saxs':\n",
    "    mask_path = '/XF11ID/analysis/2017_3/masks/'\n",
    "    mask_name = 'Nov17_SAXS.npy'\n",
    "    \n",
    "    #mask_path = '/XF11ID/analysis/2017_2/masks/'\n",
    "    #mask_name = 'Jul26_SAXS.npy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = load_mask(mask_path, mask_name, plot_ =  False, image_name = uidstr + '_mask', reverse= True ) \n",
    "mask *= pixel_mask\n",
    "show_img(mask,image_name = uidstr + '_mask', save=True, path=data_dir, aspect=1, center=center[::-1])\n",
    "mask_load=mask.copy()\n",
    "imgsa = apply_mask( imgs, mask )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Check several frames average  intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_choice_N = 3\n",
    "img_samp_index = random.sample( range(len(imgs)), img_choice_N) \n",
    "avg_img =  get_avg_img( imgsa, img_samp_index, plot_ = False, uid =uidstr)\n",
    "if avg_img.max() == 0:\n",
    "    print('There are no photons recorded for this uid: %s'%uid)\n",
    "    print('The data analysis should be terminated! Please try another uid.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show_img( imgsa[1000],  vmin=.1, vmax= 1e1, logs=True, aspect=1,\n",
    "#         image_name= uidstr + '_img_avg',  save=True, path=data_dir,  cmap = cmap_albula )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "show_img( imgs[10],  vmin=.0, vmax= 1e1, logs=False, aspect=1, #save_format='tif',\n",
    "         image_name= uidstr + '_img_avg',  save=True, path=data_dir, cmap=cmap_albula,center=center[::-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress Data\n",
    "* Generate a compressed data with filename\n",
    "* Replace old mask with a new mask with removed hot pixels\n",
    "* Do average image\n",
    "* Do each image sum\n",
    "* Find badframe_list for where image sum above bad_pixel_threshold\n",
    "* Check shutter open frame to get good time series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compress=True\n",
    "photon_occ = len( np.where(avg_img)[0] ) / ( imgsa[0].size)\n",
    "#compress =  photon_occ < .4  #if the photon ocupation < 0.5, do compress\n",
    "print (\"The non-zeros photon occupation is %s.\"%( photon_occ))\n",
    "print(\"Will \" + 'Always ' + ['NOT', 'DO'][compress]  + \" apply compress process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_start = 5  #5  #make the good_start at least 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_frame =  False # True  #generally make bin_frame as False\n",
    "if bin_frame:\n",
    "    bin_frame_number=4\n",
    "    acquisition_period = md['acquire period']\n",
    "    timeperframe = acquisition_period * bin_frame_number\n",
    "else:\n",
    "    bin_frame_number =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t0= time.time()\n",
    "if bin_frame_number==1:\n",
    "    filename = '/XF11ID/analysis/Compressed_Data' +'/uid_%s.cmp'%md['uid']\n",
    "else:\n",
    "    filename = '/XF11ID/analysis/Compressed_Data' +'/uid_%s_bined--%s.cmp'%(md['uid'],bin_frame_number) \n",
    "mask, avg_img, imgsum, bad_frame_list = compress_eigerdata(imgs, mask, md, filename, \n",
    "         force_compress= force_compress,  para_compress= para_compress,  bad_pixel_threshold = 1e14,\n",
    "                        bins=bin_frame_number, num_sub= 100, num_max_para_process= 500, with_pickle=True  )\n",
    "min_inten = 10    \n",
    "good_start = max(good_start, np.where( np.array(imgsum) > min_inten )[0][0] )    \n",
    "print ('The good_start frame number is: %s '%good_start)\n",
    "FD = Multifile(filename, good_start, len(imgs)//bin_frame_number)\n",
    "#FD = Multifile(filename, good_start, 100)\n",
    "uid_ = uidstr + '_fra_%s_%s'%(FD.beg, FD.end)\n",
    "print( uid_ )\n",
    "plot1D( y = imgsum[ np.array( [i for i in np.arange(good_start, len(imgsum)) if i not in bad_frame_list])],\n",
    "       title =uidstr + '_imgsum', xlabel='Frame', ylabel='Total_Intensity', legend='imgsum'   )\n",
    "Nimg = Nimg/bin_frame_number\n",
    "\n",
    "run_time(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_img( avg_img,   vmin=.0001, vmax= 5e4, logs=True, aspect=1, #save_format='tif',\n",
    "         image_name= uidstr + '_img_avg',  save=True, path=data_dir,  cmap = cmap_albula, center=center[::-1] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get bad frame list by a polynominal fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_end= None # 2000  \n",
    "if good_end is not None:\n",
    "    FD = Multifile(filename, good_start, min( len(imgs)//bin_frame_number, good_end) )\n",
    "    uid_ = uidstr + '_fra_%s_%s'%(FD.beg, FD.end)\n",
    "    print( uid_ )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_define_good_start =False\n",
    "if re_define_good_start:\n",
    "    good_start = 10\n",
    "    good_end = 19700\n",
    "    FD = Multifile(filename, good_start, good_end) \n",
    "    uid_ = uidstr + '_fra_%s_%s'%(FD.beg, FD.end)\n",
    "    print( FD.beg, FD.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bad_frame_list =  get_bad_frame_list( imgsum, fit='both',  plot=True,polyfit_order = 30,                                      \n",
    "                        scale= 3.5,  good_start = good_start, good_end=good_end, uid= uidstr, path=data_dir)\n",
    "\n",
    "print( 'The bad frame list length is: %s'%len(bad_frame_list) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creat new mask by masking the bad pixels and get new avg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgsum_y = imgsum[ np.array( [i for i in np.arange( len(imgsum)) if i not in bad_frame_list])]\n",
    "imgsum_x = np.arange( len( imgsum_y))\n",
    "save_lists(  [imgsum_x, imgsum_y], label=['Frame', 'Total_Intensity'],\n",
    "           filename=uidstr + '_img_sum_t', path= data_dir  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot time~ total intensity of each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot1D( y = imgsum_y, title = uidstr + '_img_sum_t', xlabel='Frame', c='b',\n",
    "       ylabel='Total_Intensity', legend='imgsum', save=True, path=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAXS Scattering Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scat_geometry =='saxs':\n",
    "    ## Get circular average| * Do plot and save q~iq\n",
    "    hmask = create_hot_pixel_mask( avg_img, threshold = 1e2, center=center, center_radius= 100)\n",
    "    mask = mask * hmask\n",
    "    qp_saxs, iq_saxs, q_saxs = get_circular_average( avg_img, mask * hmask, pargs=setup_pargs  )\n",
    "    plot_circular_average( qp_saxs, iq_saxs, q_saxs,  pargs=setup_pargs, \n",
    "                      xlim=[q_saxs.min(), q_saxs.max()*1.0], ylim = [iq_saxs.min(), iq_saxs.max()] )\n",
    "#mask =np.array( mask * hmask, dtype=bool) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%run ~/chxanalys_link/chxanalys/chx_compress_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scat_geometry =='saxs':    \n",
    "    if run_fit_form:        \n",
    "        form_res = fit_form_factor( q_saxs,iq_saxs,  guess_values={'radius': 2500, 'sigma':0.05, \n",
    "         'delta_rho':1E-10 },  fit_range=[0.0001, 0.015], fit_variables={'radius': T, 'sigma':T, \n",
    "         'delta_rho':T},  res_pargs=setup_pargs, xlim=[0.0001, 0.015])  \n",
    "        \n",
    "    qr = np.array( [qval_dict[k][0] for k in sorted( qval_dict.keys())] )\n",
    "    print(len(qr))\n",
    "    show_ROI_on_image( avg_img, roi_mask, center, label_on = False, rwidth = 840, alpha=.9,  \n",
    "                 save=True, path=data_dir, uid=uidstr, vmin= 1e-3,\n",
    "                 vmax= 1e3, #np.max(avg_img),\n",
    "                 aspect=1,\n",
    "                 show_roi_edge=True,\n",
    "                 show_ang_cor = True) \n",
    "    plot_qIq_with_ROI( q_saxs, iq_saxs, np.unique(qr), logs=True, uid=uidstr, xlim=[0.0001,0.08],\n",
    "                  ylim = [iq_saxs.min(), iq_saxs.max()*2],  save=True, path=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Depedent I(q) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scat_geometry =='saxs':\n",
    "    Nimg = FD.end - FD.beg \n",
    "    time_edge = create_time_slice( Nimg, slice_num= 4, slice_width= 1, edges = None )\n",
    "    time_edge =  np.array( time_edge ) + good_start\n",
    "    #print( time_edge )    \n",
    "    qpt, iqst, qt = get_t_iqc( FD, time_edge, mask, pargs=setup_pargs, nx=1500, show_progress= False )\n",
    "    plot_t_iqc( qt, iqst, time_edge, pargs=setup_pargs, xlim=[qt.min(), qt.max()],\n",
    "           ylim = [iqst.min(), iqst.max()], save=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_invariant_analysis:\n",
    "    if scat_geometry =='saxs':\n",
    "        invariant = get_iq_invariant( qt, iqst )\n",
    "        time_stamp = time_edge[:,0] * timeperframe\n",
    "\n",
    "    if scat_geometry =='saxs':\n",
    "        plot_q2_iq( qt, iqst, time_stamp,pargs=setup_pargs,ylim=[ -0.001, 0.01] , \n",
    "                   xlim=[0.007,0.2],legend_size= 6  )\n",
    "\n",
    "    if scat_geometry =='saxs':\n",
    "        plot_time_iq_invariant( time_stamp, invariant, pargs=setup_pargs,  )\n",
    "\n",
    "    if False:\n",
    "        iq_int = np.zeros( len(iqst) )\n",
    "        fig, ax = plt.subplots()\n",
    "        q = qt\n",
    "        for i in range(iqst.shape[0]):\n",
    "            yi = iqst[i] * q**2\n",
    "            iq_int[i] = yi.sum()\n",
    "            time_labeli = 'time_%s s'%( round(  time_edge[i][0] * timeperframe, 3) )\n",
    "            plot1D( x = q, y = yi, legend= time_labeli, xlabel='Q (A-1)', ylabel='I(q)*Q^2', title='I(q)*Q^2 ~ time',\n",
    "                   m=markers[i], c = colors[i], ax=ax, ylim=[ -0.001, 0.01] , xlim=[0.007,0.2],\n",
    "                  legend_size=4)\n",
    "\n",
    "        #print( iq_int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GiSAXS Scattering Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scat_geometry =='gi_saxs':    \n",
    "    plot_qzr_map(  qr_map, qz_map, inc_x0, ticks = ticks, data= avg_img, uid= uidstr, path = data_dir   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Analysis for gisaxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scat_geometry =='gi_saxs':    \n",
    "    #roi_masks, qval_dicts = get_gisaxs_roi( Qrs, Qzs, qr_map, qz_map, mask= mask )\n",
    "    show_qzr_roi( avg_img, roi_masks, inc_x0, ticks[:4], alpha=0.5, save=True, path=data_dir, uid=uidstr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if  scat_geometry =='gi_saxs':    \n",
    "    Nimg = FD.end - FD.beg \n",
    "    time_edge = create_time_slice( N= Nimg, slice_num= 2, slice_width= 2, edges = None )\n",
    "    time_edge =  np.array( time_edge ) + good_start\n",
    "    print( time_edge )    \n",
    "    qrt_pds = get_t_qrc( FD, time_edge, Qrs, Qzs, qr_map, qz_map, mask=mask, path=data_dir, uid = uidstr )    \n",
    "    plot_qrt_pds( qrt_pds, time_edge, qz_index = 0, uid = uidstr, path =  data_dir )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Profile Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if  scat_geometry =='gi_saxs':\n",
    "    if run_profile_plot:\n",
    "        xcorners= [ 1100, 1250, 1250, 1100 ]\n",
    "        ycorners= [ 850, 850, 950, 950 ]   \n",
    "        waterfall_roi_size = [ xcorners[1] - xcorners[0],  ycorners[2] - ycorners[1]  ]\n",
    "        waterfall_roi =  create_rectangle_mask(  avg_img, xcorners, ycorners   )\n",
    "        #show_img( waterfall_roi * avg_img,  aspect=1,vmin=.001, vmax=1, logs=True, )\n",
    "        wat = cal_waterfallc( FD, waterfall_roi, qindex= 1, bin_waterfall=True,\n",
    "                              waterfall_roi_size = waterfall_roi_size,save =True, path=data_dir, uid=uidstr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if  scat_geometry =='gi_saxs':\n",
    "    if run_profile_plot:\n",
    "        plot_waterfallc( wat, qindex=1, aspect=None, vmin=1, vmax= np.max( wat), uid=uidstr, save =True, \n",
    "                        path=data_dir, beg= FD.beg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Analysis for gi_saxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if scat_geometry =='gi_saxs':       \n",
    "    show_qzr_roi( avg_img, roi_mask, inc_x0, ticks[:4], alpha=0.5, save=True, path=data_dir, uid=uidstr )        \n",
    "    ## Get 1D Curve (Q||-intensity)\n",
    "    qr_1d_pds = cal_1d_qr( avg_img, Qr, Qz, qr_map, qz_map, inc_x0= None, mask=mask, setup_pargs=setup_pargs )\n",
    "    plot_qr_1d_with_ROI( qr_1d_pds, qr_center=np.unique( np.array(list( qval_dict.values() ) )[:,0] ),\n",
    "                    loglog=False, save=True, uid=uidstr, path = data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GiWAXS Scattering Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scat_geometry =='gi_waxs':\n",
    "    badpixel = np.where( avg_img[:600,:] >=300 )\n",
    "    roi_mask[badpixel] = 0\n",
    "    show_ROI_on_image( avg_img, roi_mask, label_on = True,  alpha=.5,\n",
    "                 save=True, path=data_dir, uid=uidstr, vmin=0.1, vmax=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract the labeled array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qind, pixelist = roi.extract_label_indices(roi_mask)\n",
    "noqs = len(np.unique(qind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of pixels in each q box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nopr = np.bincount(qind, minlength=(noqs+1))[1:]\n",
    "nopr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check one ROI intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roi_inten = check_ROI_intensity( avg_img, roi_mask, ring_number= 2, uid =uidstr ) #roi starting from 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a waterfall analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run_waterfall = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qth_interest = 5 #the second ring. #qth_interest starting from 1\n",
    "if scat_geometry =='saxs' or scat_geometry =='gi_waxs':\n",
    "    if run_waterfall:    \n",
    "        wat = cal_waterfallc( FD, roi_mask, qindex= qth_interest, save =True, path=data_dir, uid=uidstr)\n",
    "        plot_waterfallc( wat, qth_interest, aspect= None, vmin=1e-1, vmax= wat.max(), uid=uidstr, save =True, \n",
    "                        path=data_dir, beg= FD.beg, cmap = cmap_vge )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ring_avg = None    \n",
    "if run_t_ROI_Inten:\n",
    "    times_roi, mean_int_sets = cal_each_ring_mean_intensityc(FD, roi_mask, timeperframe = None, multi_cor=True  ) \n",
    "    plot_each_ring_mean_intensityc( times_roi, mean_int_sets,  uid = uidstr, save=True, path=data_dir )\n",
    "    roi_avg = np.average( mean_int_sets, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis for mass center of reflective beam center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_get_mass_center:\n",
    "    cx, cy = get_mass_center_one_roi(FD, roi_mask, roi_ind=25)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_get_mass_center:\n",
    "    fig,ax=plt.subplots(2)\n",
    "    plot1D( cx, m='o', c='b',ax=ax[0], legend='mass center-refl_X', \n",
    "           ylim=[940, 960], ylabel='posX (pixel)')\n",
    "    plot1D( cy, m='s', c='r',ax=ax[1], legend='mass center-refl_Y', \n",
    "           ylim=[1540, 1544], xlabel='frames',ylabel='posY (pixel)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## One time Correlation\n",
    "\n",
    "Note : Enter the number of buffers for Muliti tau one time correlation\n",
    "number of buffers has to be even. More details in https://github.com/scikit-beam/scikit-beam/blob/master/skbeam/core/correlation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if define another good_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "define_good_series = False\n",
    "#define_good_series = True\n",
    "\n",
    "if define_good_series:\n",
    "    good_start = 200\n",
    "    FD = Multifile(filename, beg = good_start, end = 800) #end=1000)\n",
    "    uid_ = uidstr + '_fra_%s_%s'%(FD.beg, FD.end)\n",
    "    print( uid_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%run /home/yuzhang/chxanalys_link/chxanalys/chx_generic_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_sqnorm:#for transmision SAXS\n",
    "    norm = get_pixelist_interp_iq( qp_saxs, iq_saxs, roi_mask, center)\n",
    "    print('Using circular average in the normalization of G2 for SAXS scattering.')\n",
    "elif use_SG:#for Gi-SAXS or WAXS\n",
    "    avg_imgf = sgolay2d( avg_img, window_size= 11, order= 5) * mask\n",
    "    norm=np.ravel(avg_imgf)[pixelist]    \n",
    "    print('Using smoothed image by SavitzkyGolay filter in the normalization of G2.')    \n",
    "else:     \n",
    "    norm= None\n",
    "    print('Using simple (average) normalization of G2.')      \n",
    "\n",
    "if use_imgsum_norm:\n",
    "    imgsum_ = imgsum\n",
    "else:\n",
    "    imgsum_ = None    \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#show_img( FD.rdframe(10), label_array=roi_mask, aspect=1, center=center )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_one_time: \n",
    "    t0 = time.time()    \n",
    "    g2, lag_steps  = cal_g2p( FD,  roi_mask, bad_frame_list,good_start, num_buf = 8, num_lev= None,\n",
    "                            imgsum= imgsum_, norm=norm )\n",
    "    run_time(t0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lag_steps = lag_steps[:g2.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_one_time:\n",
    "    \n",
    "    taus = lag_steps * timeperframe    \n",
    "    try:\n",
    "        g2_pds = save_g2_general( g2, taus=taus,qr= np.array( list( qval_dict.values() ) )[:,0],\n",
    "                                            qz = np.array( list( qval_dict.values() ) )[:,1],\n",
    "                             uid=uid_+'_g2.csv', path= data_dir, return_res=True )\n",
    "    except:\n",
    "        g2_pds = save_g2_general( g2, taus=taus,qr= np.array( list( qval_dict.values() ) )[:,0],                                             \n",
    "                             uid=uid_+'_g2.csv', path= data_dir, return_res=True )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#g2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_one_time:\n",
    "    g2_fit_result, taus_fit, g2_fit = get_g2_fit_general( g2,  taus, \n",
    "                function = fit_g2_func,  vlim=[0.95, 1.05], fit_range= None,  \n",
    "            fit_variables={'baseline':True, 'beta': True, 'alpha':True,'relaxation_rate':True,},                                  \n",
    "            guess_values={'baseline':1.0,'beta': 0.1,'alpha':1.0,'relaxation_rate':0.0100,},\n",
    "            guess_limits = dict( baseline =[1, 1.8], alpha=[0, 2],\n",
    "                        beta = [0, 1], relaxation_rate= [0.00001, 5000]) ,) \n",
    "    g2_fit_paras = save_g2_fit_para_tocsv(g2_fit_result,  filename= uid_  +'_g2_fit_paras.csv', path=data_dir ) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(scat_geometry_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_g2_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_one_time:\n",
    "    plot_g2_general( g2_dict={1:g2, 2:g2_fit}, taus_dict={1:taus, 2:taus_fit}, vlim=[0.95, 1.05],\n",
    "                qval_dict = qval_dict, fit_res= g2_fit_result,  geometry= scat_geometry_,filename= uid_+'_g2', \n",
    "        path= data_dir, function= fit_g2_func,  ylabel='g2', append_name=  '_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_one_time:\n",
    "    if False:\n",
    "        fs, fe = 0, 9\n",
    "        fs,fe=0, 12\n",
    "        qval_dict_ = {k:qval_dict[k] for k in list(qval_dict.keys())[fs:fe]  }\n",
    "        D0, qrate_fit_res = get_q_rate_fit_general(  qval_dict_, g2_fit_paras['relaxation_rate'][fs:fe], \n",
    "                                                   geometry=  scat_geometry_ )\n",
    "        plot_q_rate_fit_general( qval_dict_, g2_fit_paras['relaxation_rate'][fs:fe],  qrate_fit_res, \n",
    "                                geometry= scat_geometry_,uid=uid_  , path= data_dir )\n",
    "    else:\n",
    "        D0, qrate_fit_res = get_q_rate_fit_general(  qval_dict, g2_fit_paras['relaxation_rate'],\n",
    "                                    fit_range=[0, 26],   geometry= scat_geometry_ )    \n",
    "        plot_q_rate_fit_general( qval_dict, g2_fit_paras['relaxation_rate'],  qrate_fit_res,   \n",
    "                            geometry=  scat_geometry_,uid=uid_  ,\n",
    "                                show_fit=False, path= data_dir, plot_all_range=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot1D( x= qr, y=g2_fit_paras['beta'], ls='-', m = 'o', c='b', ylabel=r'$\\beta$', xlabel=r'$Q( \\AA^{-1} ) $' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For two-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "define_good_series = False\n",
    "#define_good_series = True\n",
    "if define_good_series:\n",
    "    good_start = 5\n",
    "    FD = Multifile(filename, beg = good_start, end = 1000)\n",
    "    uid_ = uidstr + '_fra_%s_%s'%(FD.beg, FD.end)\n",
    "    print( uid_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%run chxanalys_link/chxanalys/chx_generic_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_pixel = None\n",
    "if run_two_time:    \n",
    "    data_pixel =   Get_Pixel_Arrayc( FD, pixelist,  norm= norm ).get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t0=time.time()\n",
    "g12b=None\n",
    "if run_two_time:     \n",
    "    g12b = auto_two_Arrayc(  data_pixel,  roi_mask, index = None   )\n",
    "    if run_dose:\n",
    "        np.save( data_dir + 'uid=%s_g12b'%uid, g12b)\n",
    "run_time( t0 )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%run chxanalys_link/chxanalys/Two_Time_Correlation_Function.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_two_time:\n",
    "    show_C12(g12b, q_ind=3, qlabel=qval_dict,N1= FD.beg,logs=False, N2=min( FD.end,10000), vmin= 1.01, vmax=1.12, \n",
    "             timeperframe=timeperframe,save=True, path= data_dir, uid = uid_ ,cmap=cmap_albula)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_tau_steps = True\n",
    "if run_two_time:\n",
    "    if lag_steps is None:\n",
    "        num_bufs=8\n",
    "        noframes = FD.end - FD.beg\n",
    "        num_levels = int(np.log( noframes/(num_bufs-1))/np.log(2) +1) +1\n",
    "        tot_channels, lag_steps, dict_lag = multi_tau_lags(num_levels, num_bufs)\n",
    "        max_taus= lag_steps.max()\n",
    "        \n",
    "    #max_taus= lag_steps.max()  \n",
    "    max_taus = Nimg    \n",
    "    t0=time.time()\n",
    "    #tausb = np.arange( g2b.shape[0])[:max_taus] *timeperframe\n",
    "    if multi_tau_steps:\n",
    "        lag_steps_ = lag_steps[   lag_steps <= g12b.shape[0] ]\n",
    "        g2b = get_one_time_from_two_time(g12b)[lag_steps_]\n",
    "        tausb = lag_steps_ *timeperframe\n",
    "    else:\n",
    "        tausb = (np.arange( g12b.shape[0]) *timeperframe)[:-200]\n",
    "        g2b = (get_one_time_from_two_time(g12b))[:-200]\n",
    "    run_time(t0)\n",
    "         \n",
    "    g2b_pds = save_g2_general( g2b, taus=tausb, qr= np.array( list( qval_dict.values() ) )[:,0],\n",
    "                              qz=None, uid=uid_ +'_g2b.csv', path= data_dir, return_res=True )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_two_time:    \n",
    "    g2b_fit_result, tausb_fit, g2b_fit = get_g2_fit_general( g2b,  tausb, \n",
    "                function = fit_g2_func,  vlim=[0.95, 1.05], fit_range= None,  \n",
    "            fit_variables={'baseline':False, 'beta': True, 'alpha':False,'relaxation_rate':True},                                  \n",
    "            guess_values={'baseline':1.0,'beta': 0.15,'alpha':1.0,'relaxation_rate':1,},\n",
    "            guess_limits = dict( baseline =[1, 1.8], alpha=[0, 2],\n",
    "                        beta = [0, 1], relaxation_rate= [0.000001, 5000]) ) \n",
    "    g2b_fit_paras = save_g2_fit_para_tocsv(g2b_fit_result,  filename= uid_  +'_g2b_fit_paras.csv', path=data_dir )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot1D( x = tausb[1:], y =g2b[1:,0], ylim=[0.95, 1.46], xlim = [0.0001, 10], m='', c='r', ls = '-',\n",
    "#       logx=True, title='one_time_corelation', xlabel = r\"$\\tau $ $(s)$\",    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_two_time:\n",
    "    plot_g2_general( g2_dict={1:g2b, 2:g2b_fit}, taus_dict={1:tausb, 2:tausb_fit}, vlim=[0.95, 1.05],\n",
    "                qval_dict=qval_dict, fit_res= g2b_fit_result,  geometry=scat_geometry_,filename=uid_+'_g2', \n",
    "                    path= data_dir, function= fit_g2_func,  ylabel='g2', append_name=  '_b_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_two_time:    \n",
    "    if False:\n",
    "        fs, fe = 0,9\n",
    "        fs, fe = 0,12\n",
    "        qval_dict_ = {k:qval_dict[k] for k in list(qval_dict.keys())[fs:fe]  }\n",
    "        D0b, qrate_fit_resb = get_q_rate_fit_general(  qval_dict_, g2b_fit_paras['relaxation_rate'][fs:fe], geometry= scat_geometry_ )\n",
    "        plot_q_rate_fit_general( qval_dict_, g2b_fit_paras['relaxation_rate'][fs:fe],  qrate_fit_resb, \n",
    "                            geometry= scat_geometry_,uid=uid_ +'_two_time' , path= data_dir )\n",
    "    else:\n",
    "    \n",
    "        D0b, qrate_fit_resb = get_q_rate_fit_general(  qval_dict, g2b_fit_paras['relaxation_rate'],\n",
    "                                        fit_range=[0, 10],  geometry= scat_geometry_ )\n",
    "        plot_q_rate_fit_general( qval_dict, g2b_fit_paras['relaxation_rate'],  qrate_fit_resb,   \n",
    "                            geometry= scat_geometry_,uid=uid_ +'_two_time', show_fit=False,path= data_dir, plot_all_range= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_two_time and run_one_time:\n",
    "    plot_g2_general( g2_dict={1:g2, 2:g2b}, taus_dict={1:taus, 2:tausb},vlim=[0.99, 1.007],\n",
    "                qval_dict=qval_dict, g2_labels=['from_one_time', 'from_two_time'],\n",
    "            geometry=scat_geometry_,filename=uid_+'_g2_two_g2', path= data_dir, ylabel='g2', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Dose dependent analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_dose:\n",
    "    get_two_time_mulit_uids( [uid], roi_mask,  norm= norm,  bin_frame_number=1, \n",
    "                        path= data_dir0, force_generate=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print( md['transmission'] )\n",
    "except:\n",
    "    md['transmission'] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exposuretime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_dose:\n",
    "    N = len(imgs)\n",
    "    print(N)\n",
    "    #exposure_dose = md['transmission'] * exposuretime* np.int_([  N/32, N/16, N/8, N/4 ,N/2, 3*N/4, N*0.99 ])\n",
    "    exposure_dose = md['transmission'] * exposuretime* np.int_([   N/8, N/4 ,N/2, 3*N/4, N*0.99 ])\n",
    "    \n",
    "    print( exposure_dose )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_dose:\n",
    "    taus_uids, g2_uids = get_series_one_time_mulit_uids( [ uid ],  qval_dict, good_start=good_start,  \n",
    "                    path= data_dir0, exposure_dose = exposure_dose,  num_bufs =8, save_g2= False,\n",
    "                                                   dead_time = 0, trans = [ md['transmission'] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_dose:    \n",
    "    plot_dose_g2( taus_uids, g2_uids, ylim=[0.98, 1.2], vshift= 0.00,\n",
    "                 qval_dict = qval_dict, fit_res= None,  geometry= scat_geometry_,\n",
    "                 filename= '%s_dose_analysis'%uid_, \n",
    "                path= data_dir, function= None,  ylabel='g2_Dose', g2_labels= None, append_name=  '' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_dose:\n",
    "    qth_interest = 2\n",
    "    plot_dose_g2( taus_uids, g2_uids, qth_interest= qth_interest, ylim=[0.98, 1.25], vshift= 0.00,\n",
    "                 qval_dict = qval_dict, fit_res= None,  geometry= scat_geometry_,\n",
    "                 filename= '%s_dose_analysis'%uidstr, \n",
    "                path= data_dir, function= None,  ylabel='g2_Dose', g2_labels= None, append_name=  '' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Four Time Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_four_time:\n",
    "    t0=time.time()\n",
    "    g4 = get_four_time_from_two_time(g12b, g2=g2b)[:max_taus]\n",
    "    run_time(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_four_time:\n",
    "    taus4 = np.arange( g4.shape[0])*timeperframe        \n",
    "    g4_pds = save_g2_general( g4, taus=taus4, qr=np.array( list( qval_dict.values() ) )[:,0],\n",
    "                             qz=None, uid=uid_ +'_g4.csv', path= data_dir, return_res=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_four_time:\n",
    "    plot_g2_general( g2_dict={1:g4}, taus_dict={1:taus4},vlim=[0.95, 1.05], qval_dict=qval_dict, fit_res= None, \n",
    "                geometry=scat_geometry_,filename=uid_+'_g4',path= data_dir,   ylabel='g4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speckle Visiblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run_xsvs =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_xsvs:    \n",
    "    max_cts = get_max_countc(FD, roi_mask )    \n",
    "    #max_cts = 15 #for eiger 500 K\n",
    "    qind, pixelist = roi.extract_label_indices(   roi_mask  )\n",
    "    noqs = len( np.unique(qind) )\n",
    "    nopr = np.bincount(qind, minlength=(noqs+1))[1:]\n",
    "    #time_steps = np.array( utils.geometric_series(2,   len(imgs)   ) )\n",
    "    time_steps = [0,1]  #only run the first two levels\n",
    "    num_times = len(time_steps)    \n",
    "    times_xsvs = exposuretime + (2**(  np.arange( len(time_steps) ) ) -1 ) * timeperframe   \n",
    "    print( 'The max counts are: %s'%max_cts )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do historam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_xsvs:\n",
    "    if roi_avg is  None:\n",
    "        times_roi, mean_int_sets = cal_each_ring_mean_intensityc(FD, roi_mask, timeperframe = None,  ) \n",
    "        roi_avg = np.average( mean_int_sets, axis=0)\n",
    "    \n",
    "    t0=time.time()\n",
    "    spec_bins, spec_his, spec_std, spec_sum  =  xsvsp( FD, np.int_(roi_mask), norm=None,\n",
    "                max_cts=int(max_cts+2),  bad_images=bad_frame_list, only_two_levels=True )    \n",
    "    spec_kmean =  np.array(  [roi_avg * 2**j for j in  range( spec_his.shape[0] )] )\n",
    "    run_time(t0)\n",
    "    spec_pds =  save_bin_his_std( spec_bins, spec_his, spec_std, filename=uid_+'_spec_res.csv', path=data_dir ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do historam fit by negtive binominal function with maximum likehood method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_xsvs:    \n",
    "    ML_val, KL_val,K_ = get_xsvs_fit(  spec_his, spec_sum, spec_kmean, \n",
    "                        spec_std, max_bins=2, fit_range=[1,60], varyK= False  )\n",
    "    #print( 'The observed average photon counts are: %s'%np.round(K_mean,4))\n",
    "    #print( 'The fitted average photon counts are: %s'%np.round(K_,4)) \n",
    "    print( 'The difference sum of average photon counts between fit and data are: %s'%np.round( \n",
    "            abs(np.sum( spec_kmean[0,:] - K_ )),4))\n",
    "    print( '#'*30)\n",
    "    qth=   0 \n",
    "    print( 'The fitted M for Qth= %s are: %s'%(qth, ML_val[qth]) )\n",
    "    print( K_[qth])\n",
    "    print( '#'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot fit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_xsvs:   \n",
    "    qr = [qval_dict[k][0] for k in list(qval_dict.keys()) ]\n",
    "    plot_xsvs_fit(  spec_his, ML_val, KL_val, K_mean = spec_kmean, spec_std=spec_std,\n",
    "                  xlim = [0,10], vlim =[.9, 1.1],\n",
    "        uid=uid_, qth= qth_interest, logy= True, times= times_xsvs, q_ring_center=qr, path=data_dir)\n",
    "    \n",
    "    plot_xsvs_fit(  spec_his, ML_val, KL_val, K_mean = spec_kmean, spec_std = spec_std,\n",
    "                  xlim = [0,15], vlim =[.9, 1.1],\n",
    "        uid=uid_, qth= None, logy= True, times= times_xsvs, q_ring_center=qr, path=data_dir )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if run_xsvs:\n",
    "    contrast_factorL = get_contrast( ML_val)\n",
    "    spec_km_pds = save_KM(  spec_kmean, KL_val, ML_val, qs=qr, level_time=times_xsvs, uid=uid_, path = data_dir )\n",
    "    #spec_km_pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot contrast with g2 restuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_xsvs:    \n",
    "    plot_g2_contrast( contrast_factorL, g2b, times_xsvs, tausb, qr, \n",
    "                     vlim=[0.8,1.2], qth = qth_interest, uid=uid_,path = data_dir, legend_size=14)\n",
    "\n",
    "    plot_g2_contrast( contrast_factorL, g2b, times_xsvs, tausb, qr, \n",
    "                     vlim=[0.8,1.2], qth = None, uid=uid_,path = data_dir, legend_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from chxanalys.chx_libs import cmap_vge, cmap_albula, Javascript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Export Results to a HDF5 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md['mask_file']= mask_path + mask_name\n",
    "md['roi_mask_file']= fp\n",
    "md['mask'] = mask\n",
    "md['NOTEBOOK_FULL_PATH'] =  data_dir + get_current_pipeline_fullpath(NFP).split('/')[-1]\n",
    "md['good_start'] = good_start\n",
    "md['bad_frame_list'] = bad_frame_list\n",
    "md['avg_img'] = avg_img\n",
    "md['roi_mask'] = roi_mask\n",
    "md['setup_pargs'] = setup_pargs\n",
    "if scat_geometry == 'gi_saxs':        \n",
    "    md['Qr'] = Qr\n",
    "    md['Qz'] = Qz\n",
    "    md['qval_dict'] = qval_dict\n",
    "    md['beam_center_x'] =  inc_x0\n",
    "    md['beam_center_y']=   inc_y0\n",
    "    md['beam_refl_center_x'] = refl_x0\n",
    "    md['beam_refl_center_y'] = refl_y0\n",
    "\n",
    "\n",
    "elif scat_geometry == 'gi_waxs':\n",
    "    md['beam_center_x'] =  center[1]\n",
    "    md['beam_center_y']=  center[0]\n",
    "else:\n",
    "    md['qr']= qr\n",
    "    #md['qr_edge'] = qr_edge\n",
    "    md['qval_dict'] = qval_dict\n",
    "    md['beam_center_x'] =  center[1]\n",
    "    md['beam_center_y']=  center[0]            \n",
    "\n",
    "md['beg'] = FD.beg\n",
    "md['end'] = FD.end\n",
    "md['qth_interest'] = qth_interest\n",
    "md['metadata_file'] = data_dir + 'uid=%s_md.pkl'%uid\n",
    "psave_obj(  md, data_dir + 'uid=%s_md.pkl'%uid ) #save the setup parameters\n",
    "save_dict_csv( md,  data_dir + 'uid=%s_md.csv'%uid, 'w')\n",
    "\n",
    "Exdt = {} \n",
    "if scat_geometry == 'gi_saxs':  \n",
    "    for k,v in zip( ['md', 'roi_mask','qval_dict','avg_img','mask','pixel_mask', 'imgsum', 'bad_frame_list', 'qr_1d_pds'], \n",
    "                [md,    roi_mask, qval_dict, avg_img,mask,pixel_mask, imgsum, bad_frame_list, qr_1d_pds] ):\n",
    "        Exdt[ k ] = v\n",
    "elif scat_geometry == 'saxs': \n",
    "    for k,v in zip( ['md', 'q_saxs', 'iq_saxs','iqst','qt','roi_mask','qval_dict','avg_img','mask','pixel_mask', 'imgsum', 'bad_frame_list'], \n",
    "                [md, q_saxs, iq_saxs, iqst, qt,roi_mask, qval_dict, avg_img,mask,pixel_mask, imgsum, bad_frame_list] ):\n",
    "        Exdt[ k ] = v\n",
    "elif scat_geometry == 'gi_waxs': \n",
    "    for k,v in zip( ['md', 'roi_mask','qval_dict','avg_img','mask','pixel_mask', 'imgsum', 'bad_frame_list'], \n",
    "                [md,       roi_mask, qval_dict, avg_img,mask,pixel_mask, imgsum, bad_frame_list] ):\n",
    "        Exdt[ k ] = v\n",
    "        \n",
    "if run_waterfall:Exdt['wat'] =  wat\n",
    "if run_t_ROI_Inten:Exdt['times_roi'] = times_roi;Exdt['mean_int_sets']=mean_int_sets\n",
    "if run_one_time:\n",
    "    if run_invariant_analysis:\n",
    "        for k,v in zip( ['taus','g2','g2_fit_paras', 'time_stamp','invariant'], [taus,g2,g2_fit_paras,time_stamp,invariant] ):Exdt[ k ] = v\n",
    "    else:\n",
    "        for k,v in zip( ['taus','g2','g2_fit_paras'  ], [taus,g2,g2_fit_paras ] ):Exdt[ k ] = v\n",
    "            \n",
    "if run_two_time:\n",
    "    for k,v in zip( ['tausb','g2b','g2b_fit_paras', 'g12b'], [tausb,g2b,g2b_fit_paras,g12b] ):Exdt[ k ] = v\n",
    "    #for k,v in zip( ['tausb','g2b','g2b_fit_paras', ], [tausb,g2b,g2b_fit_paras] ):Exdt[ k ] = v    \n",
    "if run_dose:\n",
    "    for k,v in zip( [ 'taus_uids', 'g2_uids' ], [taus_uids, g2_uids] ):Exdt[ k ] = v\n",
    "if run_four_time:\n",
    "    for k,v in zip( ['taus4','g4'], [taus4,g4] ):Exdt[ k ] = v\n",
    "if run_xsvs:\n",
    "    for k,v in zip( ['spec_kmean','spec_pds','times_xsvs','spec_km_pds','contrast_factorL'], \n",
    "                   [ spec_kmean,spec_pds,times_xsvs,spec_km_pds,contrast_factorL] ):Exdt[ k ] = v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%run chxanalys_link/chxanalys/Create_Report.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_xpcs_results_to_h5( 'uid=%s_Isotropic_Res.h5'%md['uid'], data_dir, export_dict = Exdt )\n",
    "#extract_dict = extract_xpcs_results_from_h5( filename = 'uid=%s_Res.h5'%md['uid'], import_dir = data_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract_dict = extract_xpcs_results_from_h5( filename = 'uid=%s_Res.h5'%md['uid'], import_dir = data_dir )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creat PDF Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdf_out_dir = os.path.join('/XF11ID/analysis/', CYCLE, username, 'Results/')\n",
    "\n",
    "pdf_filename = \"XPCS_Analysis_Report2_for_uid=%s%s.pdf\"%(uid,pdf_version)\n",
    "if run_xsvs:\n",
    "    pdf_filename = \"XPCS_XSVS_Analysis_Report_for_uid=%s%s.pdf\"%(uid,pdf_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run /home/yuzhang/chxanalys_link/chxanalys/Create_Report.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#md['detector_distance'] = 4.8884902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_pdf_report( data_dir, uid, pdf_out_dir, pdf_filename, username, \n",
    "                    run_fit_form,run_one_time, run_two_time, run_four_time, run_xsvs, run_dose,\n",
    "                report_type= scat_geometry, report_invariant= run_invariant_analysis,\n",
    "               md = md )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Attach the PDF report to Olog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%run  /home/yuzhang/chxanalys_link/chxanalys/chx_olog.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if att_pdf_report:     \n",
    "    os.environ['HTTPS_PROXY'] = 'https://proxy:8888'\n",
    "    os.environ['no_proxy'] = 'cs.nsls2.local,localhost,127.0.0.1'\n",
    "    update_olog_uid_with_file( uid[:6], text='Add XPCS Analysis PDF Report', \n",
    "                              filename=pdf_out_dir + pdf_filename, append_name='_r1' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the current pipeline in Results folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_current_pipeline( NFP, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_current_pipeline_fullpath(NFP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CHX (current)",
   "language": "python",
   "name": "analysis-17q3.0_srv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
